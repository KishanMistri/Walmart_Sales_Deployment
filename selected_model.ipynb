{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b26b20b-ee95-4d7b-bff6-d745301990cc",
   "metadata": {},
   "source": [
    "<h2><center>Walmart Sales Forecasting</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e312353-3384-4b75-bed2-6e463ce96f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:43:41.067339Z",
     "iopub.status.busy": "2022-10-15T15:43:41.067070Z",
     "iopub.status.idle": "2022-10-15T15:43:42.365486Z",
     "shell.execute_reply": "2022-10-15T15:43:42.364923Z",
     "shell.execute_reply.started": "2022-10-15T15:43:41.067299Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from downcast import reduce\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9697a119-f406-4a41-96fd-d6d833a09e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:43:42.367107Z",
     "iopub.status.busy": "2022-10-15T15:43:42.366725Z",
     "iopub.status.idle": "2022-10-15T15:43:42.371367Z",
     "shell.execute_reply": "2022-10-15T15:43:42.370702Z",
     "shell.execute_reply.started": "2022-10-15T15:43:42.367090Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Env variables\n",
    "non_day_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "level_groupings = {1: [],   #Day sales accorss everything. [Results in single row with column of each day sales.]\n",
    "                   2: [\"state_id\"], \n",
    "                   3: [\"store_id\"], \n",
    "                   4: [\"cat_id\"], \n",
    "                   5: [\"dept_id\"], \n",
    "                   6: [\"state_id\", \"cat_id\"], \n",
    "                   7: [\"state_id\", \"dept_id\"], \n",
    "                   8: [\"store_id\", \"cat_id\"], \n",
    "                   9: [\"store_id\", \"dept_id\"],\n",
    "                   10:[\"item_id\"], \n",
    "                   11:[\"item_id\", \"state_id\"],\n",
    "                   12:[]  #[\"item_id\", \"store_id\"] == 'id'\n",
    "                   }\n",
    "project_path = \"~/Desktop/workspace/Walmart_Sales_Deployment/\"\n",
    "data_dir = project_path+\"dataset/\"\n",
    "processed_fpath = project_path+'processing_data/'\n",
    "submission_dir = project_path+'outputs/'\n",
    "\n",
    "random_state = 11223300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e44f4bb-1168-4a49-8202-1987842ade8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:43:42.372947Z",
     "iopub.status.busy": "2022-10-15T15:43:42.372530Z",
     "iopub.status.idle": "2022-10-15T15:44:54.594275Z",
     "shell.execute_reply": "2022-10-15T15:44:54.593703Z",
     "shell.execute_reply.started": "2022-10-15T15:43:42.372922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales=pd.read_csv(data_dir+'sales_train_evaluation.csv')\n",
    "calendar=pd.read_csv(data_dir+'calendar.csv')\n",
    "prices=pd.read_csv(data_dir+'sell_prices.csv')\n",
    "\n",
    "# This will take some time\n",
    "sales=reduce(sales)\n",
    "calendar=reduce(calendar)\n",
    "prices=reduce(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609199f-3a85-4985-8f1c-49abc58a9460",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d23da8d-28dd-4338-b91f-46452f72c495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:44:54.595003Z",
     "iopub.status.busy": "2022-10-15T15:44:54.594850Z",
     "iopub.status.idle": "2022-10-15T15:44:54.599217Z",
     "shell.execute_reply": "2022-10-15T15:44:54.598626Z",
     "shell.execute_reply.started": "2022-10-15T15:44:54.594988Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If day is weekend or not\n",
    "calendar['Weekend'] = calendar['weekday'].apply(lambda day: 1 if day.lower() == 'saturday' or day.lower() == 'sunday' else 0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba31107-8c59-457c-b472-a3d80960484f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:44:54.600317Z",
     "iopub.status.busy": "2022-10-15T15:44:54.600123Z",
     "iopub.status.idle": "2022-10-15T15:44:54.604278Z",
     "shell.execute_reply": "2022-10-15T15:44:54.603584Z",
     "shell.execute_reply.started": "2022-10-15T15:44:54.600302Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get day of the Month from data object\n",
    "calendar['Day_Of_Month'] = calendar['date'].dt.day.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b190d39-7d4d-4774-8353-52a0513f7c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:44:54.605725Z",
     "iopub.status.busy": "2022-10-15T15:44:54.605341Z",
     "iopub.status.idle": "2022-10-15T15:44:54.628626Z",
     "shell.execute_reply": "2022-10-15T15:44:54.627998Z",
     "shell.execute_reply.started": "2022-10-15T15:44:54.605703Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_Of_Month</th>\n",
       "      <th>ET1_Cultural</th>\n",
       "      <th>ET1_National</th>\n",
       "      <th>ET1_Religious</th>\n",
       "      <th>ET1_Sporting</th>\n",
       "      <th>ET2_Cultural</th>\n",
       "      <th>ET2_National</th>\n",
       "      <th>ET2_Religious</th>\n",
       "      <th>ET2_Sporting</th>\n",
       "      <th>total_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>2015-09-10</td>\n",
       "      <td>11532</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>d_1686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>11533</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>d_1689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  wm_yr_wk   weekday  wday  month  year       d event_name_1  \\\n",
       "1685 2015-09-10     11532  Thursday     6      9  2015  d_1686          NaN   \n",
       "1688 2015-09-13     11533    Sunday     2      9  2015  d_1689          NaN   \n",
       "\n",
       "     event_type_1 event_name_2  ... Day_Of_Month  ET1_Cultural  ET1_National  \\\n",
       "1685          NaN          NaN  ...           10             0             0   \n",
       "1688          NaN          NaN  ...           13             0             0   \n",
       "\n",
       "      ET1_Religious  ET1_Sporting  ET2_Cultural  ET2_National  ET2_Religious  \\\n",
       "1685              0             0             0             0              0   \n",
       "1688              0             0             0             0              0   \n",
       "\n",
       "      ET2_Sporting  total_events  \n",
       "1685             0             0  \n",
       "1688             0             0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OnehotEncoding for event types\n",
    "OHE_df = pd.get_dummies(calendar[['event_type_1','event_type_1']], prefix=['ET1', 'ET2'],dtype = np.int8)\n",
    "cols = OHE_df.columns\n",
    "OHE_df['total_events'] = OHE_df[cols].sum(axis = 1).astype(np.int8)\n",
    "calendar = pd.concat([calendar,OHE_df],axis=1)\n",
    "del OHE_df\n",
    "del cols\n",
    "calendar.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50e1ad5-e5a3-4461-bf36-984e3b6e1bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:44:54.631240Z",
     "iopub.status.busy": "2022-10-15T15:44:54.631078Z",
     "iopub.status.idle": "2022-10-15T15:44:54.634693Z",
     "shell.execute_reply": "2022-10-15T15:44:54.633924Z",
     "shell.execute_reply.started": "2022-10-15T15:44:54.631224Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop reduandant columns\n",
    "calendar.drop(['date','weekday','wday','event_name_1','event_type_1','event_name_2','event_type_2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ef576a-00d2-4c06-b71e-e62d5cde4c5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:44:54.635711Z",
     "iopub.status.busy": "2022-10-15T15:44:54.635465Z",
     "iopub.status.idle": "2022-10-15T15:44:54.651325Z",
     "shell.execute_reply": "2022-10-15T15:44:54.650769Z",
     "shell.execute_reply.started": "2022-10-15T15:44:54.635688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Day_Of_Month</th>\n",
       "      <th>ET1_Cultural</th>\n",
       "      <th>ET1_National</th>\n",
       "      <th>ET1_Religious</th>\n",
       "      <th>ET1_Sporting</th>\n",
       "      <th>ET2_Cultural</th>\n",
       "      <th>ET2_National</th>\n",
       "      <th>ET2_Religious</th>\n",
       "      <th>ET2_Sporting</th>\n",
       "      <th>total_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wm_yr_wk  month  year    d  snap_CA  snap_TX  snap_WI  Weekend  \\\n",
       "0     11101      1  2011  d_1        0        0        0        1   \n",
       "1     11101      1  2011  d_2        0        0        0        1   \n",
       "2     11101      1  2011  d_3        0        0        0        0   \n",
       "3     11101      2  2011  d_4        1        1        0        0   \n",
       "4     11101      2  2011  d_5        1        0        1        0   \n",
       "\n",
       "   Day_Of_Month  ET1_Cultural  ET1_National  ET1_Religious  ET1_Sporting  \\\n",
       "0            29             0             0              0             0   \n",
       "1            30             0             0              0             0   \n",
       "2            31             0             0              0             0   \n",
       "3             1             0             0              0             0   \n",
       "4             2             0             0              0             0   \n",
       "\n",
       "   ET2_Cultural  ET2_National  ET2_Religious  ET2_Sporting  total_events  \n",
       "0             0             0              0             0             0  \n",
       "1             0             0              0             0             0  \n",
       "2             0             0              0             0             0  \n",
       "3             0             0              0             0             0  \n",
       "4             0             0              0             0             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar = reduce(calendar)\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65bb3e2b-bef9-4390-acdf-031ce63fa006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:44:54.652182Z",
     "iopub.status.busy": "2022-10-15T15:44:54.651952Z",
     "iopub.status.idle": "2022-10-15T15:44:54.696915Z",
     "shell.execute_reply": "2022-10-15T15:44:54.696320Z",
     "shell.execute_reply.started": "2022-10-15T15:44:54.652161Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          30490\n",
       "item_id      3049\n",
       "dept_id         7\n",
       "cat_id          3\n",
       "store_id       10\n",
       "state_id        3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[['id','item_id','dept_id','cat_id','store_id','state_id']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb1bbec-5be5-4d85-8821-8897b7177bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:44:54.697889Z",
     "iopub.status.busy": "2022-10-15T15:44:54.697620Z",
     "iopub.status.idle": "2022-10-15T15:45:20.043357Z",
     "shell.execute_reply": "2022-10-15T15:45:20.042729Z",
     "shell.execute_reply.started": "2022-10-15T15:44:54.697867Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>ET1_Cultural</th>\n",
       "      <th>ET1_National</th>\n",
       "      <th>ET1_Religious</th>\n",
       "      <th>ET1_Sporting</th>\n",
       "      <th>ET2_Cultural</th>\n",
       "      <th>ET2_National</th>\n",
       "      <th>ET2_Religious</th>\n",
       "      <th>ET2_Sporting</th>\n",
       "      <th>total_events</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id    d  units_sold  wm_yr_wk  month  ...  ET1_Cultural  ET1_National  \\\n",
       "0       CA  d_1           0     11101      1  ...             0             0   \n",
       "1       CA  d_1           0     11101      1  ...             0             0   \n",
       "2       CA  d_1           0     11101      1  ...             0             0   \n",
       "3       CA  d_1           0     11101      1  ...             0             0   \n",
       "4       CA  d_1           0     11101      1  ...             0             0   \n",
       "\n",
       "   ET1_Religious  ET1_Sporting  ET2_Cultural  ET2_National  ET2_Religious  \\\n",
       "0              0             0             0             0              0   \n",
       "1              0             0             0             0              0   \n",
       "2              0             0             0             0              0   \n",
       "3              0             0             0             0              0   \n",
       "4              0             0             0             0              0   \n",
       "\n",
       "   ET2_Sporting  total_events  sell_price  \n",
       "0             0             0         NaN  \n",
       "1             0             0         NaN  \n",
       "2             0             0         NaN  \n",
       "3             0             0         NaN  \n",
       "4             0             0         NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "sales=pd.melt(sales,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],var_name='d',value_name='units_sold')\n",
    "sales=pd.merge(sales,calendar,on='d',how='left')\n",
    "sales=pd.merge(sales,prices,on=['item_id','store_id','wm_yr_wk'],how='left')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39bf0247-68f8-4013-a4cf-b3e23f348a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:45:20.045167Z",
     "iopub.status.busy": "2022-10-15T15:45:20.044531Z",
     "iopub.status.idle": "2022-10-15T15:45:20.048568Z",
     "shell.execute_reply": "2022-10-15T15:45:20.048006Z",
     "shell.execute_reply.started": "2022-10-15T15:45:20.045134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No need after melt & merging\n",
    "del calendar\n",
    "del prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "387c2ad5-c708-4d30-a753-217ae18d2b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:45:20.049790Z",
     "iopub.status.busy": "2022-10-15T15:45:20.049544Z",
     "iopub.status.idle": "2022-10-15T15:45:27.674113Z",
     "shell.execute_reply": "2022-10-15T15:45:27.673472Z",
     "shell.execute_reply.started": "2022-10-15T15:45:20.049770Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "item_id          0\n",
       "dept_id          0\n",
       "cat_id           0\n",
       "store_id         0\n",
       "state_id         0\n",
       "d                0\n",
       "units_sold       0\n",
       "wm_yr_wk         0\n",
       "month            0\n",
       "year             0\n",
       "snap_CA          0\n",
       "snap_TX          0\n",
       "snap_WI          0\n",
       "Weekend          0\n",
       "Day_Of_Month     0\n",
       "ET1_Cultural     0\n",
       "ET1_National     0\n",
       "ET1_Religious    0\n",
       "ET1_Sporting     0\n",
       "ET2_Cultural     0\n",
       "ET2_National     0\n",
       "ET2_Religious    0\n",
       "ET2_Sporting     0\n",
       "total_events     0\n",
       "sell_price       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To impute the NaN's of sell_prices, we will take average prices of product grouped.\n",
    "sales['sell_price']=sales['sell_price'].fillna(sales.groupby('id')['sell_price'].transform('mean'))\n",
    "sales.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc8e44e3-3dd9-4f6d-a02c-9b14d591d7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:49:32.901102Z",
     "iopub.status.busy": "2022-10-15T15:49:32.900143Z",
     "iopub.status.idle": "2022-10-15T15:50:04.663133Z",
     "shell.execute_reply": "2022-10-15T15:50:04.662563Z",
     "shell.execute_reply.started": "2022-10-15T15:49:32.901018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['map_id.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the categories along with their codes\n",
    "map_id = dict(zip(sales.id.cat.codes, sales.id))\n",
    "map_item_id = dict(zip(sales.item_id.cat.codes, sales.item_id))\n",
    "map_dept_id = dict(zip(sales.dept_id.cat.codes, sales.dept_id))\n",
    "map_cat_id = dict(zip(sales.cat_id.cat.codes, sales.cat_id))\n",
    "map_store_id = dict(zip(sales.store_id.cat.codes, sales.store_id))\n",
    "map_state_id = dict(zip(sales.state_id.cat.codes, sales.state_id))\n",
    "\n",
    "joblib.dump(map_id,'map_id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e3e782f-967c-4d02-845d-f12953cb5201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:52:56.201962Z",
     "iopub.status.busy": "2022-10-15T15:52:56.201090Z",
     "iopub.status.idle": "2022-10-15T15:52:56.318997Z",
     "shell.execute_reply": "2022-10-15T15:52:56.318420Z",
     "shell.execute_reply.started": "2022-10-15T15:52:56.201885Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 64.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>units_sold</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>ET1_Cultural</th>\n",
       "      <th>ET1_National</th>\n",
       "      <th>ET1_Religious</th>\n",
       "      <th>ET1_Sporting</th>\n",
       "      <th>ET2_Cultural</th>\n",
       "      <th>ET2_National</th>\n",
       "      <th>ET2_Religious</th>\n",
       "      <th>ET2_Sporting</th>\n",
       "      <th>total_events</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.943359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id    d  units_sold  \\\n",
       "0  14370     1437        3       1         0         0  d_1           0   \n",
       "1  14380     1438        3       1         0         0  d_1           0   \n",
       "2  14390     1439        3       1         0         0  d_1           0   \n",
       "3  14400     1440        3       1         0         0  d_1           0   \n",
       "4  14410     1441        3       1         0         0  d_1           0   \n",
       "\n",
       "   wm_yr_wk  month  ...  ET1_Cultural  ET1_National  ET1_Religious  \\\n",
       "0     11101      1  ...             0             0              0   \n",
       "1     11101      1  ...             0             0              0   \n",
       "2     11101      1  ...             0             0              0   \n",
       "3     11101      1  ...             0             0              0   \n",
       "4     11101      1  ...             0             0              0   \n",
       "\n",
       "   ET1_Sporting  ET2_Cultural  ET2_National  ET2_Religious  ET2_Sporting  \\\n",
       "0             0             0             0              0             0   \n",
       "1             0             0             0              0             0   \n",
       "2             0             0             0              0             0   \n",
       "3             0             0             0              0             0   \n",
       "4             0             0             0              0             0   \n",
       "\n",
       "   total_events  sell_price  \n",
       "0             0    8.281250  \n",
       "1             0    3.970703  \n",
       "2             0    2.970703  \n",
       "3             0    4.527344  \n",
       "4             0    2.943359  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labelling the categories provided.\n",
    "category=['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "for cat in tqdm(category):\n",
    "    sales[cat] = sales[cat].cat.codes\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8934214-f216-485c-a252-37cf27ebbfab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T15:52:56.828270Z",
     "iopub.status.busy": "2022-10-15T15:52:56.827657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales['d']  = sales['d'].apply(lambda s: int(s.split('_')[1]))\n",
    "sales = reduce(sales)\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83514d1a-875f-46a9-b444-4f5078e08f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intermediate_df = sales.groupby(['id'])['units_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98ba38-8be2-4d75-8516-ff633e01e936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rolling Window Statistics\n",
    "window_size = [7,14,21,28,35,42,49,56,63] \n",
    "for window in tqdm(window_size):\n",
    "    sales['mean_units_rolling_'+str(window)] = intermediate_df\\\n",
    "                                .transform(lambda x: x.rolling(window=window).mean())\\\n",
    "                                .fillna(0)\\\n",
    "                                .astype(np.float16)\n",
    "    \n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b0271-a3ee-4433-b2c0-928349f3eb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lags\n",
    "most_useful_lags = [7,14,21,28,35,42,70]\n",
    "for lag in tqdm(most_useful_lags):\n",
    "    sales['lag_'+str(lag)] = intermediate_df.shift(lag).fillna(0)\n",
    "    \n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863882d2-01b3-47ab-bcdd-874b118d6f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rolling window median and Standard Deviation\n",
    "window_size = [7,14,21,28,35,42,70] \n",
    "for window in window_size:\n",
    "    sales['median_units_rolling_'+str(window)] = intermediate_df\\\n",
    "                                    .transform(lambda x: x.rolling(window=window).median())\\\n",
    "                                    .astype(np.float16)\n",
    "    sales['std_units_rolling_'+str(window)] = intermediate_df\\\n",
    "                                    .transform(lambda x: x.rolling(window=window).std())\\\n",
    "                                    .astype(np.float16)\n",
    "\n",
    "sales.fillna(0, inplace=True)\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3ab2e3-b13d-4eb8-9ac6-d371af27a642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Expanding Window Stats\n",
    "for window in window_size:\n",
    "    sales['mean_units_expanding_'+str(window)] = intermediate_df\\\n",
    "                                      .transform(lambda x: x.expanding(window).mean())\\\n",
    "                                      .astype(np.float16)\n",
    "\n",
    "    sales['median_units_expanding_'+str(window)] = intermediate_df\\\n",
    "                                      .transform(lambda x: x.expanding(window).median())\\\n",
    "                                      .astype(np.float16)\n",
    "\n",
    "    sales['std_units_expanding_'+str(window)] = intermediate_df\\\n",
    "                                      .transform(lambda x: x.expanding(window).median())\\\n",
    "                                      .astype(np.float16)\n",
    "\n",
    "sales.fillna(0, inplace=True)    \n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b9c24-0659-4f38-ae58-f28c85fa0081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selling Trend feature\n",
    "sales['daily_avg_units'] = sales.groupby(['id','d'])['units_sold'].transform('mean').fillna(0)\n",
    "sales['avg_units'] = intermediate_df.transform('mean').fillna(0)\n",
    "\n",
    "sales['selling_trend'] = (sales['daily_avg_units'] - sales['avg_units'])\n",
    "\n",
    "sales.drop(['daily_avg_units','avg_units'],axis=1,inplace=True)\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0879fd-cf7e-4eab-b45b-5508e6507554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean Encoding features\n",
    "sales['mean_units_by_item'] = df.groupby('item_id',as_index=False, sort=False)['units']\\\n",
    "                                                     .transform('mean')\\\n",
    "                                                     .astype(np.float16)\n",
    "sales['mean_units_by_state'] = df.groupby('state_id',as_index=False, sort=False)['units']\\\n",
    "                                                      .transform('mean')\\\n",
    "                                                      .astype(np.float16)\n",
    "sales['mean_units_by_store'] = df.groupby('store_id',as_index=False, sort=False)['units']\\\n",
    "                                                      .transform('mean')\\\n",
    "                                                      .astype(np.float16)\n",
    "sales['mean_units_by_cat'] = df.groupby('cat_id',as_index=False, sort=False)['units']\\\n",
    "                                                    .transform('mean')\\\n",
    "                                                    .astype(np.float16)\n",
    "sales['mean_units_by_dept'] = df.groupby('dept_id',as_index=False, sort=False)['units']\\\n",
    "                                                     .transform('mean')\\\n",
    "                                                     .astype(np.float16)\n",
    "\n",
    "sales['mean_units_by_cat_dept'] = df.groupby(['cat_id','dept_id'],as_index=False, sort=False)['units']\\\n",
    "                                                         .transform('mean')\\\n",
    "                                                         .astype(np.float16)\n",
    "sales['mean_units_by_store_item'] = df.groupby(['store_id','item_id'],as_index=False, sort=False)['units']\\\n",
    "                                                           .transform('mean')\\\n",
    "                                                           .astype(np.float16)\n",
    "sales['mean_units_by_cat_item'] = df.groupby(['cat_id','item_id'],as_index=False, sort=False)['units']\\\n",
    "                                                         .transform('mean')\\\n",
    "                                                         .astype(np.float16)\n",
    "sales['mean_units_by_dept_item'] = df.groupby(['dept_id','item_id'],as_index=False, sort=False)['units']\\\n",
    "                                                          .transform('mean')\\\n",
    "                                                          .astype(np.float16)\n",
    "sales['mean_units_by_state_store'] = df.groupby(['state_id','store_id'],as_index=False, sort=False)['units']\\\n",
    "                                                            .transform('mean')\\\n",
    "                                                            .astype(np.float16)\n",
    "\n",
    "sales['mean_units_by_state_store_cat'] = df.groupby(['state_id','store_id','cat_id'],as_index=False, sort=False)['units']\\\n",
    "                                                                .transform('mean')\\\n",
    "                                                                .astype(np.float16)\n",
    "sales['mean_units_by_store_cat_dept'] = df.groupby(['store_id','cat_id','dept_id'],as_index=False, sort=False)['units']\\\n",
    "                                                               .transform('mean')\\\n",
    "                                                               .astype(np.float16)\n",
    "\n",
    "sales.fillna(0, inplace=True)\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df1a95-c919-4328-a4f5-5da55363bb13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Metric function - RMSSE\n",
    "\n",
    "def RMSE(actual,predictions):\n",
    "    if type(actual) != 'numpy.ndarray':\n",
    "        actual = np.array(actual)\n",
    "    if type(predictions) != 'numpy.ndarray':\n",
    "        predictions = np.array(predictions)\n",
    "    assert actual.shape[0] == predictions.shape[0], \"Observation count Mismatched...!\"\n",
    "    assert len(actual.shape) == 1 and len(predictions.shape) == 1, \"RMSE takes single dimension list...\"\n",
    "    \n",
    "    return round(np.sqrt(((actual-predictions)**2).mean()),3)\n",
    "\n",
    "def RMSSE(y_actual, y_pred, train_series, axis=1):\n",
    "    assert axis == 0 or axis == 1\n",
    "    if type(y_actual) != 'numpy.ndarray': y_actual = np.array(y_actual)\n",
    "    if type(y_pred) != 'numpy.ndarray': y_pred = np.array(y_pred)\n",
    "    if type(train_series) != 'numpy.ndarray': train_series = np.array(train_series)\n",
    "    \n",
    "    assert y_actual.shape == y_pred.shape\n",
    "    \n",
    "    if axis == 1:\n",
    "        # using axis == 1 we must guarantee these are matrices and not arrays\n",
    "        assert y_actual.shape[1] > 1 and y_pred.shape[1] > 1 and train_series.shape[1] > 1\n",
    "    \n",
    "    numerator = ((y_actual - y_pred)**2).sum(axis=axis)\n",
    "    n = train_cols\n",
    "    \n",
    "    if axis == 1:\n",
    "        denominator = 1/(n-1) * ((train_series[:, 1:] - train_series[:, :-1]) ** 2).sum(axis=axis)\n",
    "    else:\n",
    "        denominator = 1/(n-1) * ((train_series[1:] - train_series[:-1]) ** 2).sum(axis=axis)\n",
    "    return ((1/forcasting_horizon) * numerator/denominator) ** 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ca347-6bba-4113-88d9-4bc274d3e95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Utility Functions\n",
    "# Submission Format df\n",
    "def submission(X_test, y_test, predictions):\n",
    "    \"\"\"\n",
    "    >> submission(X_test, y_test, predictions)\n",
    "    Inputs:\n",
    "        i)   X_test must have 2 columns: \n",
    "                -> 'id' : integer values id's which will be used for getting mapped product ids\n",
    "                -> 'd'  : Day num columns with integer values only\n",
    "        ii)  y_test is original answers for ['id','d'] combinations\n",
    "        iii) predictions are pred values\n",
    "    \n",
    "    Returns:\n",
    "        df in final submission format\n",
    "    \"\"\"\n",
    "    # Getting just important cols\n",
    "    df = X_test[['id','d']]\n",
    "    df['actual'] = y_test\n",
    "    df['prediction'] = predictions\n",
    "    \n",
    "    # F_ day formatted columns\n",
    "    start = df.d.min() - 1\n",
    "    df['d'] = df['d'] - start\n",
    "    \n",
    "    # Pivot and Id string mappings\n",
    "    id_map = joblib.load('./map_id.pkl')\n",
    "    \n",
    "    valid_df = pd.pivot(df,index='id',values ='prediction',columns = 'd').reset_index()\n",
    "    valid_df['id'] = valid_df['id'].map(id_map).str.replace('evaluation','validation')\n",
    "    \n",
    "    eval_df = pd.pivot(df,index='id',values ='actual',columns = 'd').reset_index()\n",
    "    eval_df['id'] = eval_df['id'].map(id_map)\n",
    "    \n",
    "    results = pd.concat([valid_df,eval_df])\n",
    "    results = results.set_index('id').add_prefix('F').reset_index()\n",
    "    del valid_df\n",
    "    del eval_df\n",
    "    \n",
    "    return results\n",
    "    \n",
    "\n",
    "# To get RandomizedSearchCV with TimeSplit indexes provided\n",
    "def get_RS_model(estimator=None, param_distributions=None ,n_iter=3,n_jobs=1):\n",
    "    \"\"\"\n",
    "    Get the RandomizedSearchCV model object with 3-Fold TimeSplit of X_train data with Default 3 Randomized sampled parameters from each HyperParameter\n",
    "    Inputs: 1) estimator 2) param_distributions for given estimator\n",
    "    Output: RandomizedSearch \n",
    "    \"\"\"\n",
    "    return  RandomizedSearchCV(estimator, param_distributions, cv=train_test_idx,\\\n",
    "                               n_iter=n_iter, scoring='neg_mean_squared_error', n_jobs=1,random_state=random_state,\\\n",
    "                               refit=False, verbose=2, return_train_score=True)\n",
    "\n",
    "# To get feature importance bar Chart\n",
    "def plot_feature_importance(model = None, test_df = None, skip = 0):\n",
    "    \"\"\"\n",
    "    >>> Usage: plot_feature_importance(model = estimator, test_df = X_test, skip = 0)\n",
    "    skip parameter is used when the number of features are large and you want leave out/skip the least k important points in graph.\n",
    "    \"\"\"\n",
    "    features = test_df.columns\n",
    "    if hasattr(model,'coef_'):\n",
    "        importances = model.coef_\n",
    "    \n",
    "    elif hasattr(model,'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    if skip != 0:\n",
    "        indices = np.argsort(importances)[skip:]\n",
    "    else:\n",
    "        indices = np.argsort(importances)\n",
    "        \n",
    "    plt.figure(figsize=(6,8))\n",
    "    plt.barh(range(len(indices)) , importances[indices])\n",
    "    \n",
    "    plt.title('Feature Importance',fontsize=14)\n",
    "    plt.xlabel('Relative Importance',fontsize=14)\n",
    "    plt.yticks(range(len(indices)),[features[i] for i in indices])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381fb10-daf1-4b15-8e0b-d9f973b9d4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(sales,processed_fpath+'featured_data.pkl')\n",
    "del sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca59ac-a8dc-4421-82c9-ab97b5f99eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing featured data from Phase-3.1 \n",
    "data = joblib.load(processed_fpath+'featured_data.pkl')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9f3f7-cafa-467c-bbde-e497d9575b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train-Val-Test set split\n",
    "X_train = data.loc[data.d < 1886]\n",
    "y_train = X_train['units_sold']\n",
    "X_train.drop(['units_sold'], axis=1, inplace=True)\n",
    "\n",
    "# Validation dataset\n",
    "validation_days=np.arange(1886,1914)\n",
    "X_val = data.loc[data.d.isin(validation_days)]\n",
    "y_val = X_val['units_sold']\n",
    "X_val.drop(['units_sold'], axis=1, inplace=True)\n",
    "\n",
    "# Test set\n",
    "X_test  = data.loc[data.d > 1913]\n",
    "y_test  = X_test['units_sold']\n",
    "X_test.drop(['units_sold'], axis=1, inplace=True)\n",
    "\n",
    "print(\"X_train: {0} \\t y_train: {1}\\n\".format(X_train.shape,y_train.shape))\n",
    "print(\"X_val:\\t {0}\\t\\t y_val:\\t {1}\\n\".format(X_val.shape,y_val.shape))\n",
    "print(\"X_test:\\t {0}\\t\\t y_test: {1}\\n\".format(X_test.shape,y_test.shape))\n",
    "\n",
    "# For space issues\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b41b5-0cb5-4bbd-9f28-7cb2b086c720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Getting best model fit for predictions\n",
    "model = LGBMRegressor(learning_rate=0.035,\\\n",
    "                      max_depth=148,\\\n",
    "                      num_leaves=375,\\\n",
    "                      lambda_l2=0.05,\\\n",
    "                      n_estimators=100, random_state = random_state)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "yt_hat = model.predict(X_train)\n",
    "print(\"Train Error: {0}\".format(RMSE(y_train.iloc[val_idx],yt_hat)))\n",
    "\n",
    "# Validation score\n",
    "Y_hat = model.predict(X_val)\n",
    "print(\"\\nValidation Error: \",RMSE(y_val,Y_hat))\n",
    "\n",
    "model.fit(X_val,y_val)\n",
    "# Test scores\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nTest Error: \",RMSE(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe40a8b-6188-4604-af8b-e96d4f394d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting Feature Importances\n",
    "plot_feature_importance(model = model, test_df = X_test,skip=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2cc21-1f53-48ca-abe7-af54ed6e2510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Submission Format df\n",
    "sub_df = submission(X_test, y_test, predictions = y_pred)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d42b6ca-59a0-4cf5-940f-844a93a4f00d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving df and Model\n",
    "sub_df.to_csv(submission_dir+'submission_LightGBM.csv',index=False)\n",
    "joblib.dump(model,models_dir+'Model_LightGBM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec82ee-32d4-41b3-be7a-f0ab5e2d7ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleanup \n",
    "cleanup_list = [sub_df, Y_hat, y_pred, model, X, y, cv_hat]\n",
    "for obj in cleanup_list:\n",
    "    del obj\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a0ae5-1917-417c-9b67-29e6205ef57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be8360-8fd8-4128-b1ed-862d363a248e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
